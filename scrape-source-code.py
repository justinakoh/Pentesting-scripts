# Used to scrape websites written using non-compilable languages for their source code.
# TODO: Fix bug where it adds a little symbol after each file name

import os
import requests
import urllib.request
import re

def main():
    to_read = input("Enter name of file containing the file names: ")
    url = input("Enter URL: ")
    fetched_file_name = input("Enter the file you want to store the source code in: ")

    create_new_folder(fetched_file_name)
    read_file(to_read, url, fetched_file_name)
    write_summary()

# Reading the file that contains the list of names - or names that we guess exist
# TODO: Error message when you can't find the file
def read_file(to_read, url, folder):
    f = open(to_read, "r")
    all_lines = f.readlines()

    for line in all_lines:
        fetch_files(line, url, folder)

# Creates a new folder to store all the fetched files in
def create_new_folder(folder):
    new_folder = os.getcwd() + "/../../"+ folder

    if not os.path.exists(new_folder):
        os.makedirs(new_folder)
    else:
        print("Folder already exists")
        # TODO: functionality to allow people the option to overwrite

# TODO: Writes a summary for what was able to be fetched and what wasn't.
# TODO: Write as a txt or md file?
def write_summary():
    # idk write a summary i guess - maybe a table or chart - we like those
    return

# Attempts to actually get the file
# TODO: Fix it so that you can just put in the filename and this will auto add in a backslash
def fetch_files(file_name, original_url, folder):
    url = original_url + file_name
    print("--------------------------------------------------------")
    print(url)
    print("--------------------------------------------------------")

    fetched_file = requests.get(url, allow_redirects=True)
    filtered_file_name = file_name.rsplit('/', 1)[-1]
    stripped_file = re.sub(r'[^a-zA-Z0-9.]', '', filtered_file_name)
    print("========================================")
    print(stripped_file)

    file_and_location = os.getcwd() + "/../../" + folder + "/" + stripped_file
    print("========================================")
    urllib.request.urlretrieve(url, file_and_location)
    return

if __name__ == "__main__":
    main()
